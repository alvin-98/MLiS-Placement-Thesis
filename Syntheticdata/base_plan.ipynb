{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fc56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf37c6",
   "metadata": {},
   "source": [
    "## Creating some data based off the html \n",
    "#### Can be done N times in a loop to increase dataset size\n",
    "#### Can grab other html from the pdf as well to increase variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62897c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html>\n",
      "<table><thead><tr><th colspan=\"3\"><strong>Noise Charges</strong></th></tr><tr><th>QC</th><th>Set fee per Tonne 2025<br/>Day</th><th>Set fee per Tonne 2025<br/>Night</th></tr></thead><tbody><tr><td>0</td><td><span style=\"color: green;\">€2.95</span></td><td><span style=\"color: green;\">€11.11</span></td></tr><tr><td>0.125</td><td><span style=\"color: green;\">€7.11</span></td><td><span style=\"color: green;\">€4.50</span></td></tr><tr><td>0.25</td><td><span style=\"color: green;\">€9.30</span></td><td><span style=\"color: green;\">€17.82</span></td></tr><tr><td>0.5</td><td><span style=\"color: green;\">€5.68</span></td><td><span style=\"color: green;\">€21.63</span></td></tr><tr><td>1</td><td><span style=\"color: green;\">€16.87</span></td><td><span style=\"color: green;\">€16.88</span></td></tr><tr><td>2</td><td><span style=\"color: green;\">€2.08</span></td><td><span style=\"color: green;\">€1.61</span></td></tr><tr><td>4</td><td><span style=\"color: green;\">€13.65</span></td><td><span style=\"color: green;\">€12.07</span></td></tr><tr><td>8</td><td><span style=\"color: green;\">€8.77</span></td><td><span style=\"color: green;\">€3.08</span></td></tr><tr><td>16</td><td><span style=\"color: green;\">€8.15</span></td><td><span style=\"color: green;\">€19.71</span></td></tr></tbody></table>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<table><thead><tr><th colspan=\"3\"><strong>Noise Charges</strong></th></tr><tr><th>QC</th><th>Set fee per Tonne 2025<br>Day</th><th>Set fee per Tonne 2025<br>Night</th></tr></thead><tbody><tr><td>0</td><td><span style=\"color: green;\">€0.00</span></td><td><span style=\"color: green;\">€0.00</span></td></tr><tr><td>0.125</td><td><span style=\"color: green;\">€0.00</span></td><td><span style=\"color: green;\">€0.00</span></td></tr><tr><td>0.25</td><td><span style=\"color: green;\">€0.00</span></td><td><span style=\"color: green;\">€0.00</span></td></tr><tr><td>0.5</td><td><span style=\"color: green;\">€0.00</span></td><td><span style=\"color: green;\">€2.00</span></td></tr><tr><td>1</td><td><span style=\"color: green;\">€1.00</span></td><td><span style=\"color: green;\">€4.00</span></td></tr><tr><td>2</td><td><span style=\"color: green;\">€2.00</span></td><td><span style=\"color: green;\">€8.00</span></td></tr><tr><td>4</td><td><span style=\"color: green;\">€4.00</span></td><td><span style=\"color: green;\">€12.00</span></td></tr><tr><td>8</td><td><span style=\"color: green;\">€6.00</span></td><td><span style=\"color: green;\">€16.00</span></td></tr><tr><td>16</td><td><span style=\"color: green;\">€8.00</span></td><td><span style=\"color: green;\">€20.00</span></td></tr></tbody></table>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all value cells (inside <span>)\n",
    "for span in soup.find_all(\"span\"):\n",
    "    # Replace the € value with a random number\n",
    "    new_value = round(random.uniform(0, 25), 2)\n",
    "    span.string = f\"€{new_value:.2f}\"\n",
    "\n",
    "# Output updated HTML as string\n",
    "updated_html = str(soup)\n",
    "\n",
    "print(updated_html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3e83a",
   "metadata": {},
   "source": [
    "## Solution creation\n",
    "#### Can have 'correct' functions for each instance then perform '==' check using same input parameters as AI generated function to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8a4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Noise Charges                                                        \n",
      "             QC Set fee per Tonne 2025 Day Set fee per Tonne 2025 Night\n",
      "0         0.000                      €2.95                       €11.11\n",
      "1         0.125                      €7.11                        €4.50\n",
      "2         0.250                      €9.30                       €17.82\n",
      "3         0.500                      €5.68                       €21.63\n",
      "4         1.000                     €16.87                       €16.88\n",
      "5         2.000                      €2.08                        €1.61\n",
      "6         4.000                     €13.65                       €12.07\n",
      "7         8.000                      €8.77                        €3.08\n",
      "8        16.000                      €8.15                       €19.71\n",
      "168.70000000000002\n",
      "8.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3706950/2357901683.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(updated_html)\n"
     ]
    }
   ],
   "source": [
    "dfs = pd.read_html(updated_html)\n",
    "df = dfs[0]\n",
    "\n",
    "print(df)\n",
    "def extract_formula(df, qc, weight, day_night):\n",
    "    row = df[df[('Noise Charges', 'QC')] == qc]\n",
    "    if row.empty:\n",
    "        return None\n",
    "    \n",
    "    if day_night.lower() == 'day':\n",
    "        fee = row[('Noise Charges', 'Set fee per Tonne 2025 Day')].values[0]\n",
    "    elif day_night.lower() == 'night':\n",
    "        fee = row[('Noise Charges', 'Set fee per Tonne 2025 Night')].values[0]\n",
    "    else:\n",
    "        raise ValueError(\"day_night must be 'day' or 'night'\")\n",
    "    \n",
    "    total_fee = float(fee.replace('€', '').replace(',', '.')) * weight\n",
    "    return total_fee\n",
    "\n",
    "    \n",
    "print(extract_formula(df, 1, 10, 'day'))  # Example usage\n",
    "print(extract_formula(df, 2, 5, 'night'))  # Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c37e4",
   "metadata": {},
   "source": [
    "## Code below wont work on notebook - need to connect to compute node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fba2ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs01/home/ppytr13/.conda/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unable to mmap 9976570520 bytes from file </gpfs01/home/ppytr13/.cache/huggingface/hub/models--codellama--CodeLlama-7b-Python-hf/snapshots/d4178f5d2eead875e627ec487b23679266319b7f/model-00001-of-00002.safetensors>: Cannot allocate memory (12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodellama/CodeLlama-7b-Python-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your model name \u001b[39;00m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m sys_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mYou are a helpful Python programming assistant. You are given an HTML document that contains a pricing table. Your job is to write clean, readable Python code that defines a function to compute a total fee based on inputs like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, weight in tonnes, and whether it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mThe HTML may contain <th colspan> or <br> tags and style attributes. You should only provide the formula. Read the HTML and use your HTML reading abilities to understand the structure and values of the HTML and use them to make a function\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#add few shot learning? will need to produce examples\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py:309\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py:4574\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4565\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4567\u001b[0m     (\n\u001b[1;32m   4568\u001b[0m         model,\n\u001b[1;32m   4569\u001b[0m         missing_keys,\n\u001b[1;32m   4570\u001b[0m         unexpected_keys,\n\u001b[1;32m   4571\u001b[0m         mismatched_keys,\n\u001b[1;32m   4572\u001b[0m         offload_index,\n\u001b[1;32m   4573\u001b[0m         error_msgs,\n\u001b[0;32m-> 4574\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4580\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4593\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py:5020\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5018\u001b[0m \u001b[38;5;66;03m# If shard_file is \"\", we use the existing state_dict instead of loading it\u001b[39;00m\n\u001b[1;32m   5019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 5020\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\n\u001b[1;32m   5022\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5024\u001b[0m \u001b[38;5;66;03m# Fix the key names\u001b[39;00m\n\u001b[1;32m   5025\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {key_renaming_mapping[k]: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key_renaming_mapping}\n",
      "File \u001b[0;32m~/.conda/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py:530\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# Use safetensors if possible\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_safetensors_available():\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    531\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mmetadata()\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlx\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unable to mmap 9976570520 bytes from file </gpfs01/home/ppytr13/.cache/huggingface/hub/models--codellama--CodeLlama-7b-Python-hf/snapshots/d4178f5d2eead875e627ec487b23679266319b7f/model-00001-of-00002.safetensors>: Cannot allocate memory (12)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"codellama/CodeLlama-7b-Python-hf\"  # Replace with your model name \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "sys_prompt = '''You are a helpful Python programming assistant. You are given an HTML document that contains a pricing table. Your job is to write clean, readable Python code that defines a function to compute a total fee based on inputs like 'QC', weight in tonnes, and whether it's 'day' or 'night'.\n",
    "\n",
    "The HTML may contain <th colspan> or <br> tags and style attributes. You should only provide the formula. Read the HTML and use your HTML reading abilities to understand the structure and values of the HTML and use them to make a function'''\n",
    "#add few shot learning? will need to produce examples\n",
    "few_shot = f'''Example: For the following HTML table **{updated_html}** you would be expected to provide the following output **def extract_formula(df, qc, weight, day_night):\n",
    "    row = df[df[('Noise Charges', 'QC')] == qc]\n",
    "    if row.empty:\n",
    "        return None\n",
    "    \n",
    "    if day_night.lower() == 'day':\n",
    "        fee = row[('Noise Charges', 'Set fee per Tonne 2025 Day')].values[0]\n",
    "    elif day_night.lower() == 'night':\n",
    "        fee = row[('Noise Charges', 'Set fee per Tonne 2025 Night')].values[0]\n",
    "    else:\n",
    "        raise ValueError(\"day_night must be 'day' or 'night'\")\n",
    "    \n",
    "    total_fee = float(fee.replace('€', '').replace(',', '.')) * weight\n",
    "    return total_fee**'''\n",
    "user_prompt = '''\n",
    "# Below is an HTML table containing noise charge data.\n",
    "# This table is presented to you as a string for easy reading\n",
    "# Your task is to write a function `extract_formula(html_text, qc, weight, day_night)` that:\n",
    "# - Extracts the relevant fee per tonne for a given `qc` (float) and `day_night` (\"day\" or \"night\")\n",
    "# - Multiplies the fee by the given `weight` in tonnes\n",
    "# - Returns the total fee as a float\n",
    "# Output only the function definition. Do not include explanatory comments or examples.\n",
    "'''\n",
    "full_prompt = f'''\n",
    "<|system|>\n",
    "{sys_prompt}\n",
    "{few_shot}\n",
    "<|user|>\n",
    "{user_prompt}\n",
    "{html}\n",
    "<|assistant|>'''\n",
    "inputs = tokenizer(full_prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "formula = tokenizer.batch_decode(outputs[:, inputs['input_ids'].size(1):], skip_special_tokens=True)\n",
    "formula = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "formula\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
