{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5476abd0-b58d-4675-96c0-3d9f491f0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d83fd8be-a63a-4ccd-afc2-351b202b8e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbde62b23d34fc7a2a0573162bfc578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d008693-8a26-4f6c-b29a-bc55110c7bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727574e7e5734b54879c76637cc25cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<guidance.models._transformers.Transformers at 0x14db31c5a810>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import guidance\n",
    "lm = model + \"Who won the last Kentucky derby and by how much?\"\n",
    "from guidance import gen\n",
    "\n",
    "lm + gen(max_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3522dded-f2a3-4a9d-860d-4d10ce96e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae0d3d366364942a63cc97f068f51b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<guidance.models._transformers.Transformers at 0x14dafa7721d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm + '''\\\n",
    "Q: Who won the last Kentucky derby and by how much?\n",
    "A:''' + gen(stop=\"Q:\", max_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b81c6022-ab02-42bf-be4d-95bb06097175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e715f51d7949af85bccb1764c9958e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Who won the last Kentucky derby and by how much?\"\n",
    "lm = model + f'''\\\n",
    "Q: {query}\n",
    "A: {gen(name=\"answer\", stop=\"Q:\", max_tokens=50)}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b40ce3ba-72ed-467c-ab17-cb3939011db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 149th running of the Kentucky Derby was held on May 4, 2024, at Churchill Downs in Louisville, Kentucky. The winner was **Mage**, ridden by jockey **Flavien Prat** and'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[\"answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3694b0d4-db50-4d64-bce6-8dcc31d126d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219a2c61dada4654b481ff8a0445b594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<guidance.models._transformers.Transformers at 0x14dafa4bc890>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import guidance\n",
    "\n",
    "@guidance\n",
    "def qa_bot(lm, query):\n",
    "    lm += f'''\\\n",
    "    Q: {query}\n",
    "    A: {gen(name=\"answer\", stop=\"Q:\")}'''\n",
    "    return lm\n",
    "\n",
    "query = \"Who won the last Kentucky derby and by how much?\"\n",
    "model + qa_bot(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14a3b07c-df21-4742-b24b-3a9b775c108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 149th running of the Kentucky Derby was held on May 4, 2024, at Churchill Downs in Louisville, Kentucky. The winner was **Mage**, ridden by jockey **Flavien Prat** and'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[\"answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23214073-ed1c-4e2d-8c69-204577edf9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c10a128c1641869d829d7173084224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from guidance import select\n",
    "\n",
    "lm = model + f'''\\\n",
    "Q: {query}\n",
    "Now I will choose to either SEARCH the web or RESPOND.\n",
    "Choice: {select([\"SEARCH\", \"RESPOND\"], name=\"choice\")}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f17eeef4-308e-475e-b498-04ad340ce13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5adeda7f-240e-46fa-9a88-ccd4928db8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ce076f75694321a77c132e6bb5d429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@guidance\n",
    "def qa_bot(lm, query):\n",
    "    lm += f'''\\\n",
    "    Q: {query}\n",
    "    Now I will choose to either SEARCH the web or RESPOND.\n",
    "    Choice: {select([\"SEARCH\", \"RESPOND\"], name=\"choice\")}\n",
    "    '''\n",
    "    if lm[\"choice\"] == \"SEARCH\":\n",
    "        lm += \"A: I don't know, Google it!\"\n",
    "    else:\n",
    "        lm += f'A: {gen(stop=\"Q:\", name=\"answer\")}'\n",
    "    return lm\n",
    "\n",
    "lm = model + qa_bot(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db7de09f-459c-490d-ad5b-586a6a87433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(lm, \"choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b91f226-934c-435d-ad60-ffb897da7e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lm['choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8aced03-3916-48e8-8a06-ec39c83f3989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'echo': True,\n",
       " '_interpreter': <guidance.models._engine._interpreter.EngineInterpreter at 0x14db320a7cd0>,\n",
       " '_active_blocks': {},\n",
       " 'sampling_params': {},\n",
       " '_parent': <guidance.models._transformers.Transformers at 0x14dafa34a3d0>,\n",
       " '_parent_id': 1360,\n",
       " '_id': 1361,\n",
       " '_trace_nodes': {1352:[LiteralInput:\"A: I don't know, Google it!\"]:[TokenOutput:'A':True:75.94385147094727:Token(token='A', bytes=b'A', prob=nan, masked=False)],\n",
       "  1353:[]:[TokenOutput:':':True:75.94385147094727:Token(token=':', bytes=b':', prob=0.27966225147247314, masked=False)],\n",
       "  1354:[]:[TokenOutput:' I':True:75.94385147094727:Token(token=' I', bytes=b' I', prob=0.016418831422924995, masked=False)],\n",
       "  1355:[]:[TokenOutput:' don':True:75.94385147094727:Token(token=' don', bytes=b' don', prob=0.00017329071124549955, masked=False)],\n",
       "  1356:[]:[TokenOutput:\"'t\":True:75.94385147094727:Token(token=\"'t\", bytes=b\"'t\", prob=0.9999969005584717, masked=False)],\n",
       "  1357:[]:[TokenOutput:' know':True:75.94385147094727:Token(token=' know', bytes=b' know', prob=0.31745609641075134, masked=False)],\n",
       "  1358:[]:[TokenOutput:',':True:75.94385147094727:Token(token=',', bytes=b',', prob=1.8683374946704134e-05, masked=False)],\n",
       "  1359:[]:[TokenOutput:' Google':True:75.94385147094727:Token(token=' Google', bytes=b' Google', prob=7.25229182263476e-11, masked=False)],\n",
       "  1360:[]:[TokenOutput:' it':True:75.94385147094727:Token(token=' it', bytes=b' it', prob=0.5841754674911499, masked=False)],\n",
       "  1361:[]:[TokenOutput:'!':True:75.94385147094727:Token(token='!', bytes=b'!', prob=0.00037366218748502433, masked=False)]},\n",
       " 'llm': <guidance.models._transformers.Transformers at 0x14db30a1b050>}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23c62700-8038-4254-a007-807d6ccfbd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__and__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iand__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__ior__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__ror__',\n",
       " '__rsub__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__xor__',\n",
       " 'add',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'difference',\n",
       " 'difference_update',\n",
       " 'discard',\n",
       " 'intersection',\n",
       " 'intersection_update',\n",
       " 'isdisjoint',\n",
       " 'issubset',\n",
       " 'issuperset',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'symmetric_difference',\n",
       " 'symmetric_difference_update',\n",
       " 'union',\n",
       " 'update']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bba3bf72-b3ec-4d23-904c-4cbbacbc0327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97dfb2014164dc0976774573e0e9f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = model + f'''\\\n",
    "Q: {query}\n",
    "Now I will choose to either SEARCH the web or RESPOND.\n",
    "Choice: {select([\"SEARCH\", \"RESPOND\"], name=\"choice\")}\n",
    "'''\n",
    "if lm[\"choice\"] == \"SEARCH\":\n",
    "    lm += \"Here are 3 search queries:\\n\"\n",
    "    for i in range(3):\n",
    "        lm += f'''{i+1}. \"{gen(stop='\"', name=\"queries\", temperature=1.0, list_append=True)}\"\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bef222f5-f2ba-497e-b47d-e11313dea810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last kentucky derby winner and margin of victory',\n",
       " 'who won the kentucky derby 2023',\n",
       " 'kentucky derby 2023 final results']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[\"queries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2130dd9-ccef-430e-acab-29ac900ec7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e82f7128594faf8b62693531142ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can create and guide multi-turn conversations by using a series of role tags\n",
    "@guidance\n",
    "def experts(lm, query):\n",
    "    with system():\n",
    "        lm += \"You are a helpful assistant.\"\n",
    "\n",
    "    with user():\n",
    "        lm += f\"\"\"\\\n",
    "        I want a response to the following question:\n",
    "        {query}\n",
    "        Who are 3 world-class experts (past or present) who would be great at answering this?\n",
    "        Please don't answer the question or comment on it yet.\"\"\"\n",
    "\n",
    "    with assistant():\n",
    "        lm += gen(name='experts', max_tokens=300)\n",
    "    \n",
    "    with user():\n",
    "        lm += f\"\"\"\\\n",
    "        Great, now please answer the question as if these experts had collaborated in writing a joint anonymous answer.\n",
    "        In other words, their identity is not revealed, nor is the fact that there is a panel of experts answering the question.\n",
    "        If the experts would disagree, just present their different positions as alternatives in the answer itself (e.g. 'some might argue... others might argue...').\n",
    "        Please start your answer with ANSWER:\"\"\"\n",
    "    \n",
    "    with assistant():\n",
    "        lm += gen(name='answer', max_tokens=500)\n",
    "\n",
    "    return lm\n",
    "                   \n",
    "lm = model + experts(query='What is the meaning of life?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df8043-40cc-4986-89cb-e42768a257c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for part in model.stream() + experts(query='What is the meaning of life?'):\n",
    "# #     print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb73ba8-fef4-46ec-a88d-6ff493adbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "from guidance import models, system, user, assistant, json as gen_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c858ac64-a559-4dac-9db5-375b924aa6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "transfer_passenger_count = 30\n",
    "\n",
    "condition = [\n",
    "    # {\"charge_name\": \"transfer passenger charge\", \"transfer_passenger_count\": transfer_passenger_count, \"period\": \"summer airline scheduling season\", \"rate\": \"?\"},\n",
    "    # # {\"charge_name\": \"transfer passenger charge\", \"transfer_passenger_count\": transfer_passenger_count, \"period\": \"winter airline scheduling season\", \"rate\": \"?\"},\n",
    "    {\"charge_name\": \"runway landing and takeoff charge\", \"period\": \"summer airline scheduling season\", \"atm\": \"landing\", \"per tonne MTOW\": 1, \"rate\": \"?\"},\n",
    "    # # {\"charge_name\": \"runway landing and takeoff charge\", \"period\": \"summer airline scheduling season\", \"atm\": \"takeoff\", \"per tonne MTOW\": 1, \"rate\": \"?\"},\n",
    "    # # {\"charge_name\": \"runway landing and takeoff charge\", \"period\": \"winter airline scheduling season\", \"atm\": \"landing\", \"per tonne MTOW\": 1, \"rate\": \"?\"},\n",
    "    # {\"charge_name\": \"runway landing and takeoff charge\", \"period\": \"winter airline scheduling season\", \"atm\": \"takeoff\", \"per tonne MTOW\": 1, \"rate\": \"?\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1f2ab7-6761-4ffa-917d-bc306c1aeab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5534e725a75e47a296160f00c2cfd872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "MODEL_ID = \"Qwen/Qwen3-30B-A3B\"\n",
    "import torch, outlines\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 1️⃣  HF loads & shards the model – ONE LINE does the heavy lifting.\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",                # shards across all visible GPUs\n",
    "    low_cpu_mem_usage=True,           # avoids a large RAM peak\n",
    ")\n",
    "\n",
    "# 2️⃣  Wrap in Outlines.\n",
    "tok        = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# model      = outlines.from_transformers(hf_model, tok)          # note new API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45e4adb-14e1-48a2-a029-222ede8d7705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpustat is not installed, run `pip install gpustat` to collect GPU stats.\n"
     ]
    }
   ],
   "source": [
    "import guidance\n",
    "model = guidance.models.Transformers(hf_model, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df02197-6c98-42e8-8be0-54954c64599a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<guidance.models._transformers.Transformers at 0x149106843d10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35660807-0f7e-42d3-bff1-5fd4b2cc5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pydantic import BaseModel, Field, RootModel\n",
    "from typing import Optional, Union\n",
    "from enum import Enum\n",
    "from guidance import models, system, user, assistant, json as gen_json\n",
    "\n",
    "# {'type': 'VALUE',\n",
    "#  'value': 3.9,\n",
    "#  'description': 'Transfer passenger charge rate in pounds'}\n",
    "\n",
    "# 3. Define the expression tree structure\n",
    "class Op(str, Enum):\n",
    "    ADD = \"ADD\"\n",
    "    MULTIPLY = \"MULTIPLY\"\n",
    "\n",
    "class ValueNode(BaseModel):\n",
    "    \"\"\"A leaf node with a numeric value\"\"\"\n",
    "    type: str = \"VALUE\"\n",
    "    value: float\n",
    "    description: str = Field(description=\"Explanation of what this value represents\")\n",
    "\n",
    "class OpNode(BaseModel):\n",
    "    \"\"\"An operation node with two children\"\"\"\n",
    "    type: str = \"OPERATION\"\n",
    "    operator: Op\n",
    "    left: \"Node\"  # Must have both children\n",
    "    right: \"Node\"\n",
    "\n",
    "# Use discriminated union to ensure the model follows one of the valid patterns\n",
    "class Node(RootModel):\n",
    "    \"\"\"Either a value node or an operation node\"\"\"\n",
    "    root: Union[ValueNode, OpNode]\n",
    "    \n",
    "    # model_config = dict(extra=\"forbid\")\n",
    "\n",
    "# # Examples of valid expression trees\n",
    "# EXAMPLE_VALUE_NODE = ValueNode(\n",
    "#     type=\"VALUE\", \n",
    "#     value=3.9,\n",
    "#     description=\"Transfer passenger charge rate in pounds\"\n",
    "# )\n",
    "\n",
    "# EXAMPLE_OP_NODE = OpNode(\n",
    "#     type=\"OPERATION\",\n",
    "#     operator=Op.MULTIPLY,\n",
    "#     left=Node(root=ValueNode(\n",
    "#         type=\"VALUE\", \n",
    "#         value=3.9, \n",
    "#         description=\"Transfer passenger charge per passenger\"\n",
    "#     )),\n",
    "#     right=Node(root=ValueNode(\n",
    "#         type=\"VALUE\", \n",
    "#         value=30.0, \n",
    "#         description=\"Number of transfer passengers\"\n",
    "#     ))\n",
    "# )\n",
    "\n",
    "# Rebuild the model to handle the forward reference in the Node class\n",
    "# Node.model_rebuild()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53822390-c3b3-462e-9c8b-670698284df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Node.model_rebuild()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b11f11-66f4-4100-9917-61fee0e3c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"output/2025-airport-charges-terms-and-conditions/tinychargesmarkdown.md\", \"r\") as f:\n",
    "    markdown_content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb68ce3e-9964-4dbd-bd23-7a8c13908677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 6. Define the guidance program using the new chat API\n",
    "# @guidance\n",
    "# def create_expression_tree(llm, markdown_content, cond, pydantic_class):\n",
    "    \n",
    "#     with system():\n",
    "#         llm = llm + \"You are a world-class algorithm for building expression trees from text. Your goal is to construct a JSON object that represents the calculation logic for a 'rate' based on a document and a set of conditions.\"\n",
    "\n",
    "#     with user():\n",
    "#         llm += f\"\"\"Here is the document:\n",
    "# ---\n",
    "# {markdown_content}\n",
    "# ---\n",
    "\n",
    "# Given the following condition:\n",
    "# {cond}\n",
    "\n",
    "# Construct the expression tree for the rate based on the document and condition.\"\"\"\n",
    "\n",
    "#     with assistant():\n",
    "#         llm += gen_json(name=\"expression_tree\", schema=pydantic_class)\n",
    "    \n",
    "#     return llm\n",
    "\n",
    "# 6. Define the guidance program using the new chat API\n",
    "\n",
    "@guidance\n",
    "def create_expression_tree(llm, markdown_content, cond, pydantic_class):\n",
    "    \n",
    "    with system():\n",
    "        llm = llm + \"\"\"You are a world-class algorithm for building expression trees from text. Your goal is to construct a JSON object that represents the calculation logic for a 'rate' based on a document and a set of conditions.\n",
    "        \n",
    "You MUST follow the Node schema exactly. It requires either:\n",
    "1. A ValueNode with 'type': 'VALUE' and a 'value' field containing a number, OR\n",
    "2. An OpNode with 'type': 'OPERATION', an 'operator' which must be 'ADD' or 'MULTIPLY', and 'left'/'right' fields containing other nodes.\n",
    "\n",
    "Here are examples of valid expression trees:\n",
    "1. Simple value: {\"type\": \"VALUE\", \"value\": 3.9, \"description\": \"Transfer passenger charge rate in pounds\"}\n",
    "2. Simple multiplication: {\"type\": \"OPERATION\", \"operator\": \"MULTIPLY\", \"left\": {\"type\": \"VALUE\", \"value\": 3.9, \"description\": \"Transfer passenger charge per passenger\"}, \"right\": {\"type\": \"VALUE\", \"value\": 30.0, \"description\": \"Number of transfer passengers\"}}\"\"\"\n",
    "\n",
    "    with user():\n",
    "        llm += f\"\"\"Here is the document:\n",
    "---\n",
    "{markdown_content}\n",
    "---\n",
    "\n",
    "Given the following condition:\n",
    "{cond}\n",
    "\n",
    "Construct the expression tree for the rate based on the document and condition.\"\"\"\n",
    "\n",
    "    with assistant():\n",
    "        # Use stricter constraints for generation\n",
    "        llm += gen_json(\n",
    "            name=\"expression_tree\", \n",
    "            schema=pydantic_class,\n",
    "            max_tokens=200,\n",
    "            # validation_fn=lambda x: pydantic_class.model_validate_json(x) is not None\n",
    "        )\n",
    "\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9fe07e-df31-465c-853c-091a7e391334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Node"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d1cf33e-fb15-4383-aaf1-891f86586dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Condition: {'charge_name': 'runway landing and takeoff charge', 'period': 'summer airline scheduling season', 'atm': 'landing', 'per tonne MTOW': 1, 'rate': '?'} ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67cbdffcee34ecd8ca5d6dc7e8cc493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 7. Loop over conditions and generate the expression tree\n",
    "for cond in condition:\n",
    "    print(f\"--- Condition: {cond} ---\")\n",
    "    try:\n",
    "        # Execute the guidance program\n",
    "        result_lm = model + create_expression_tree(markdown_content=markdown_content, cond=cond, pydantic_class = Node)\n",
    "        print(result_lm)\n",
    "        # Extract and validate the generated JSON\n",
    "        # The output from the new API is already a Pydantic object, so no need to parse\n",
    "        expression_tree = result_lm[\"expression_tree\"]\n",
    "        # print(expression_tree.model_dump_json(indent=2))\n",
    "        # cond[\"rate\"] = expression_tree\n",
    "        print(expression_tree)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        cond[\"rate\"] = None\n",
    "\n",
    "# 8. Print the final conditions with expression trees\n",
    "# print(\"\\n--- Final Result ---\")\n",
    "# print(condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab78832f-51c0-49ab-a01d-3b0f73261aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"VALUE\", \"value\": 5.5, \"description\": \"Band 1 rate for summer season\"}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acce7c29-af71-4d82-accc-446f2c07b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_json = json.loads(expression_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5843276-3acb-4c57-bbbc-7d0d8c3471de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'VALUE', 'value': 5.5, 'description': 'Band 1 rate for summer season'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1ea4e74-31ce-40e5-85b5-be3340d8560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"VALUE\",\n",
      "    \"value\": 5.5,\n",
      "    \"description\": \"Band 1 rate for summer season\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(loaded_json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aab30d65-7f9b-48d4-ac73-7dc48175b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Node.model_validate_json(expression_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "427e87bc-c05a-4331-9c86-231da962313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "        \"type\": \"VALUE\",\n",
      "        \"value\": 5.5,\n",
      "        \"description\": \"Band 1 rate for summer season\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result.model_dump_json(indent=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "531bdc42-e2fa-4a86-bbb0-64c123278953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"VALUE\", \"value\": 3.9, \"description\": \"Transfer passenger charge rate in pounds\"}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75cd69be-00b7-4355-b774-0e86f4d4fb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_825144/440850722.py:1: DeprecationWarning: \n",
      "        The `json` function is deprecated starting from v1.0.0.\n",
      "        Do not use it. Support for it will be removed in v1.1.0.\n",
      "        Use the `Generator` object instead:\n",
      "        ```python\n",
      "        from outlines import Generator\n",
      "        from outlines.types import JsonSchema\n",
      "        schema_str = '...'  # JSON Schema as a string\n",
      "        generator = Generator(model, JsonSchema(schema_str))\n",
      "        ```\n",
      "        You can then call the generator created with a prompt to generate\n",
      "        JSON data that matches the schema.\n",
      "        \n",
      "  generator = outlines.generate.json(model, Node)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m generator = \u001b[43moutlines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/v0_legacy/generate/json.py:91\u001b[39m, in \u001b[36mjson\u001b[39m\u001b[34m(model, schema_object, sampler, whitespace_pattern)\u001b[39m\n\u001b[32m     89\u001b[39m     generator = GeneratorVisionV0Adapter(model, json_schema, sampler)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     generator = \u001b[43mGeneratorV0Adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema_object, \u001b[38;5;28mtype\u001b[39m(BaseModel)):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\n\u001b[32m     95\u001b[39m         generator,\n\u001b[32m     96\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mformat_sequence\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: schema_object.model_validate_json(x)\n\u001b[32m     98\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/v0_legacy/generate/api.py:47\u001b[39m, in \u001b[36mGeneratorV0Adapter.__init__\u001b[39m\u001b[34m(self, model, output_type, sampler)\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     43\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can only use the v0 API with models that were already\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mavailable in v0. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m     )\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28mself\u001b[39m.generator = \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.sampling_params = asdict(sampler.sampling_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/generator.py:333\u001b[39m, in \u001b[36mGenerator\u001b[39m\u001b[34m(model, output_type, processor)\u001b[39m\n\u001b[32m    331\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m SteerableGenerator.from_processor(model, processor) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSteerableGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/generator.py:220\u001b[39m, in \u001b[36mSteerableGenerator.__init__\u001b[39m\u001b[34m(self, model, output_type)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m     regex_string = to_regex(term)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28mself\u001b[39m.logits_processor = \u001b[43mRegexLogitsProcessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor_library_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/processors/structured.py:175\u001b[39m, in \u001b[36mRegexLogitsProcessor.__init__\u001b[39m\u001b[34m(self, regex_string, tokenizer, tensor_library_name)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m----------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Build a guide from the regex string and then pass it to the\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# GuideLogitsProcessor superclass.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m guide = \u001b[43mRegexGuide\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(tokenizer=tokenizer, guide=guide, tensor_library_name=tensor_library_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/processors/guide.py:161\u001b[39m, in \u001b[36mRegexGuide.from_regex\u001b[39m\u001b[34m(cls, regex_string, tokenizer, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_regex\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    142\u001b[39m     **kwargs,\n\u001b[32m    143\u001b[39m ):\n\u001b[32m    144\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a RegexGuide from a regular expression.\u001b[39;00m\n\u001b[32m    145\u001b[39m \n\u001b[32m    146\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \n\u001b[32m    160\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_regex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_create_states_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcached_create_states_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines_core/fsm/guide.py:212\u001b[39m, in \u001b[36mRegexGuide.from_regex\u001b[39m\u001b[34m(cls, regex_string, tokenizer, _create_states_mapping, device, regex_parser, frozen_tokens)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_regex\u001b[39m(\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m     frozen_tokens: List[\u001b[38;5;28mstr\u001b[39m] = [],\n\u001b[32m    207\u001b[39m ):\n\u001b[32m    208\u001b[39m     (\n\u001b[32m    209\u001b[39m         states_to_token_maps,\n\u001b[32m    210\u001b[39m         empty_token_ids,\n\u001b[32m    211\u001b[39m         fsm_finals,\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     ) = \u001b[43m_create_states_mapping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregex_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregex_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrozen_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrozen_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     eos_tensor = torch.tensor([tokenizer.eos_token_id], device=device)\n\u001b[32m    219\u001b[39m     initial_state = states_to_token_maps.get_initial_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/caching.py:138\u001b[39m, in \u001b[36mcache.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m result = wrapper.__memory__.get(cache_key, default=ENOVAL, retry=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m ENOVAL:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     result = \u001b[43mcached_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     wrapper.__memory__.set(cache_key, result, expire, retry=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines/processors/guide.py:124\u001b[39m, in \u001b[36mcached_create_states_mapping\u001b[39m\u001b[34m(regex_string, tokenizer, *args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;129m@cache\u001b[39m()\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_create_states_mapping\u001b[39m(regex_string, tokenizer, *args, **kwargs):\n\u001b[32m    123\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrap the uncached create_states_mapping function in a cache.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muncached_create_states_mapping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/outlines_core/fsm/guide.py:140\u001b[39m, in \u001b[36mcreate_states_mapping\u001b[39m\u001b[34m(regex_string, tokenizer, regex_parser, frozen_tokens)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_states_mapping\u001b[39m(\n\u001b[32m    108\u001b[39m     regex_string: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    109\u001b[39m     tokenizer,\n\u001b[32m    110\u001b[39m     regex_parser: Callable[[\u001b[38;5;28mstr\u001b[39m], interegular.Pattern] = interegular.parse_pattern,\n\u001b[32m    111\u001b[39m     frozen_tokens: List[\u001b[38;5;28mstr\u001b[39m] = [],\n\u001b[32m    112\u001b[39m ) -> Tuple[Index, Set[\u001b[38;5;28mint\u001b[39m], Set[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    113\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create the variables related to the mapping between states and tokens from a regex string.\u001b[39;00m\n\u001b[32m    114\u001b[39m \n\u001b[32m    115\u001b[39m \u001b[33;03m    The parameters of the function are used for caching purpose.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m \u001b[33;03m        A set of final states in the FSM.\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     regex_fsm = \u001b[43mregex_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m create_states_mapping_from_fsm(regex_fsm, tokenizer, frozen_tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36mPattern.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFSM\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FSM.union(*(\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:396\u001b[39m, in \u001b[36m_Concatenation.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    394\u001b[39m             current = []\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m         current.append(\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    397\u001b[39m current.append(all_.times(prefix_postfix[\u001b[32m1\u001b[39m]))\n\u001b[32m    398\u001b[39m result = FSM.concatenate(*current)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:288\u001b[39m, in \u001b[36m_Repeated.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix != (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m):\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not have prefix/postfix on CharGroup-level\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m unit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m mandatory = unit * \u001b[38;5;28mself\u001b[39m.min\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36mPattern.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFSM\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FSM.union(*(\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:396\u001b[39m, in \u001b[36m_Concatenation.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    394\u001b[39m             current = []\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m         current.append(\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    397\u001b[39m current.append(all_.times(prefix_postfix[\u001b[32m1\u001b[39m]))\n\u001b[32m    398\u001b[39m result = FSM.concatenate(*current)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:288\u001b[39m, in \u001b[36m_Repeated.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix != (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m):\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not have prefix/postfix on CharGroup-level\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m unit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m mandatory = unit * \u001b[38;5;28mself\u001b[39m.min\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36mPattern.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFSM\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FSM.union(*(\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:396\u001b[39m, in \u001b[36m_Concatenation.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    394\u001b[39m             current = []\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m         current.append(\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    397\u001b[39m current.append(all_.times(prefix_postfix[\u001b[32m1\u001b[39m]))\n\u001b[32m    398\u001b[39m result = FSM.concatenate(*current)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36mPattern.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFSM\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:453\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix_postfix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    452\u001b[39m     prefix_postfix = \u001b[38;5;28mself\u001b[39m.prefix_postfix\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FSM.union(*(\u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:396\u001b[39m, in \u001b[36m_Concatenation.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    394\u001b[39m             current = []\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m         current.append(\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_fsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    397\u001b[39m current.append(all_.times(prefix_postfix[\u001b[32m1\u001b[39m]))\n\u001b[32m    398\u001b[39m result = FSM.concatenate(*current)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/patterns.py:296\u001b[39m, in \u001b[36m_Repeated.to_fsm\u001b[39m\u001b[34m(self, alphabet, prefix_postfix, flags)\u001b[39m\n\u001b[32m    294\u001b[39m     optional.\u001b[34m__dict__\u001b[39m[\u001b[33m'\u001b[39m\u001b[33mfinals\u001b[39m\u001b[33m'\u001b[39m] |= {optional.initial}\n\u001b[32m    295\u001b[39m     optional *= (\u001b[38;5;28mself\u001b[39m.max - \u001b[38;5;28mself\u001b[39m.min)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmandatory\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/fsm.py:372\u001b[39m, in \u001b[36mFSM.__add__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m    365\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m        Concatenate two finite state machines together.\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m        For example, if self accepts \"0*\" and other accepts \"1+(0|1)\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    370\u001b[39m \u001b[33;03m        Call using \"fsm3 = fsm1 + fsm2\"\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/fsm.py:362\u001b[39m, in \u001b[36mFSM.concatenate\u001b[39m\u001b[34m(*fsms)\u001b[39m\n\u001b[32m    359\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m OblivionError\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(\u001b[38;5;28mnext\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MLiS-Placement-Thesis/pipeline/.venv/lib/python3.11/site-packages/interegular/fsm.py:1000\u001b[39m, in \u001b[36mcrawl\u001b[39m\u001b[34m(alphabet, initial, final, follow)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    999\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m         j = states.index(\u001b[38;5;28mnext\u001b[39m)\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m   1002\u001b[39m         j = \u001b[38;5;28mlen\u001b[39m(states)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "generator = outlines.generate.json(model, Node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af2496-ceeb-4027-96e1-2a8a818878ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6️⃣ Evaluation function for the expression tree\n",
    "def evaluate(node: Node, context: dict) -> float:\n",
    "    if node.value is not None:\n",
    "        if node.value.literal is not None:\n",
    "            return node.value.literal\n",
    "        if node.value.variable is not None:\n",
    "            return context.get(node.value.variable, 0)\n",
    "        return 0\n",
    "\n",
    "    if node.operator and node.childA and node.childB:\n",
    "        val_a = evaluate(node.childA, context)\n",
    "        val_b = evaluate(node.childB, context)\n",
    "\n",
    "        if node.operator == Op.ADD:\n",
    "            return val_a + val_b\n",
    "        if node.operator == Op.MULTIPLY:\n",
    "            return val_a * val_b\n",
    "        if node.operator == Op.GREATER_THAN:\n",
    "            return val_a > val_b\n",
    "        if node.operator == Op.IF:\n",
    "            # childA is condition, childB is true-branch, childC is false-branch\n",
    "            if val_a:\n",
    "                return val_b\n",
    "            elif node.childC:\n",
    "                return evaluate(node.childC, context)\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b2da8-6f05-4349-9966-d3475fe669cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7️⃣ Loop over conditions, generate and evaluate the tree\n",
    "for cond in condition:\n",
    "    prompt = f\"\"\"You are a world-class algorithm for parsing rules from text into a calculation tree.\n",
    "\n",
    "    Here is a document:\n",
    "    ---\n",
    "    {markdown_content}\n",
    "    ---\n",
    "\n",
    "    Given the following condition:\n",
    "    {cond}\n",
    "\n",
    "    Create a JSON object that represents the calculation logic for the charge as an expression tree. \n",
    "    - Use 'IF' for conditional logic.\n",
    "    - Use 'GREATER_THAN' for comparisons.\n",
    "    - Use 'MULTIPLY' and 'ADD' for arithmetic.\n",
    "    - Use 'value.literal' for numbers found in the text.\n",
    "    - Use 'value.variable' to reference keys from the condition, like 'per tonne MTOW'.\n",
    "    \"\"\"\n",
    "    tree = generator(prompt)\n",
    "    cond[\"rate\"] = evaluate(tree, cond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695853f-2323-4a5e-9ac2-ea827ea7a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8️⃣ Print the updated conditions\n",
    "import json\n",
    "print(json.dumps(condition, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
